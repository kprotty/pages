---
layout: default
title: "Atomics and Memory"
description: "Getting this 'released' 'happened-before' I 'observed' any tpyos"
---

To start, this topic seems to often be poorly misunderstood, never understood, or hard to reason about even after understanding. I can firmly say here that I don't really know what im talking about. This is just a large rant and is how I understand these things. Take of it what you will. I'll also be using [LLVM's Atomic Memory Model](https://llvm.org/docs/Atomics.html) as a basis for reasoning.

## Atomics and shared memory

Lets get some definitions out of the way: 

* Parallelism is things happening at the same time (i.e. two people, each doing their own task). 
* Concurrency is multiple things happening, but not necessarily at the same time (i.e. one person switching between tasks)
* Atomicity is something appearing to happen in its entirety, with no observable partial states. (i.e. I appear to have written this blog atomically if you don't look at my commits)

In the face of parallel execution supported by hardware, atomic operations provide ways to do things completely without interruption. This is important for synchronization between CPU cores and even more so in a preemptive scheduling environment. In practice, there are 3 classes of operations that are made atomic by the hardware:

* **Loads**: reading de memory
* **Stores**: writing de memory
* **RMW (Read Modify Write)**: reading, doing, then writing de memory

For RMW operations, the base abstraction is called [Compare and Swap](https://en.wikipedia.org/wiki/Compare-and-swap) or `CAS` for short. It serves as a general purpose RMW operation in that all others can be implemented using it. Some pseudo code of it would look something along the lines of:

```py
CAS(memory, compare_with, swap_with):
    atomically:
        tmp = LOAD(memory)
        if tmp == compare_with:
            STORE(memory, swap_with)
            return OK
        else:
            return ERROR(tmp)
```

You can then build other RMW atomic operations on top of it:

```rs
// Atomically adds `add_amount` to memory.
// Returns the old value before the add took place.
FETCH_ADD(memory, add_amount):
    old = LOAD(memory)
    loop:
        new = old + add_amount
        match CAS(memory, old, new):
            if OK: return old
            if ERROR(updated): old = updated
```

[Bonus: CAS Implementation and ABA](#ABA-Problem)

## Volatile and Side-Effects

There's a misconception that `volatile` is somehow related to threading and synchronization. This probably stemmed from Java where it makes all operations on `volatile` types [Sequentially Consistent](#Sequential-Consistency). Volatile in lower level languages, generally built on top of LLVM, refers instead to ensuring that the compiler doesn't optimize loads and stores out.

In the compiler world, common optimizations involve caching loads or eliminating/mergining stores since operations on memory are relatively more expensive to some degree. This means that how you declare memory accesses may not be how the program will ultimately access it under an optimizing compiler. This can be a good thing because you get faster code for less mental overhead. Some see it as bad thing because it either requires mental overhead to understand or doesn't produce the code they expect. A few even say that these sort of optimizations have no place in the compiler and should be the programmer's job instead (See [Program Execution 5.4.6.2](https://harelang.org/specification/)). Frankly, I don't understand this position..

Anyway, because these sort of optimizations exist you need ways to tell the compiler to screw off and let it emit what you actually intended. This is what things like inline assmebly, intrinsics, and other various attributes are used for. They represent, in some form or another, "side-effects" or black-boxes which limit the compiler's ability to reason about what it does. Volatile then just creates an arbitrary side-effect which is useful to making a read/write happen without the compiler interventing with "yea, no".

## Soundness and Undefined Behavior

This is another misunderstood part of writing programs. People often assume that certain systems programming languages are "high level assemblers" when this isn't really the case. Under this assumption, they proceed to write code that they think is mapping to some assembly and get surprised when their code fails in unexpected ways. I understand this as **programming languages having a conceptual model, not a physical model**. 

For instance, when you write C code you're writing towards the C abstract machine -- even if what you see generated from an implementation is assembly for your target. An *technically* incorrect inference is that the output reversly maps to the input: *"If i write this C, it will emit this ASM"*. Language models aren't like this, they define a set of rules about what your code will do, not how it does it. Implementations are free to make your code do the thing however they wish. Relying on implementation details, as far as the model is concerned, is (again *technically*) undefined behavior.

Undefined Behavior (or `UB` for short) is when you write code that violates the language model often by relying on assumptions that aren't apart of it. A program which contains undefined behavior is known to be "Unsound", where soundness refers to basically following the language's rules. When a program has UB, it is understood that *anything can happen* when execution -- often joked about as formatting your partitions. Practically, this just ends up being what the compiler/implementation thinks is best which may not align with your opinion of it.

UB should be avoided for many reasons, apart from the spooky fairy tales many like to proclaim. Compilers can, and will, optimize around it. This can end up in [code being deleted](https://zig.godbolt.org/z/5x6jc8KKz) or even [security risks](https://zig.godbolt.org/z/r4neb7jo1). In relation to atomics and memory, reading and writing in parallel (also known as a `data race`) is considered undefined behavior in environments like LLVM. I've anecdotaly met a lot of people who consider this to be fine because "it works most of the time". However, as they say, *"[nothing more permanent than a temporary solution](https://blog.juliobiason.me/books/things-i-learnt/permanent-solution/#:~:text=Depending%20on%20where%20you%20look,fix%20them%2C%20will%20become%20permanent.)"*. I understand the sentiment, but when you want your software to scale target wise (e.g. to multiple architectures and future compiler optimizations) this approach doesn't work. You can end up with race conditions, missing values, and all other nice UB things.

Although I talk as if from experience, i've been on both ends of the mindset spectrum and ironically flunctuate when the model i'm targetting is personally annoyingly complex (~~[cough](http://smallcultfollowing.com/babysteps/blog/2017/02/01/unsafe-code-and-shared-references/), [cough](https://plv.mpi-sws.org/rustbelt/stacked-borrows/paper.pdf)~~). I have to admit that its tempting to relying on the idea that LLVM will generate a specific instruction for something even if its not apart of the spec. My solution to keep myself in check passing it through others who sounds like they know what they're talking about and discussing why it be how it is.  

[Bonus: Modern Architectures Too Forgiving](#Too-Forgiving)

## Out-out-order Execution and Memory

TODO

## "Happens Before"

TODO

## Memory barriers

TODO

## Weakest constraint: Monotonic/Relaxed

TODO

## Release and Acquire

TODO: Ziggy mailbox illustration:
- Release:
    - Memory(`buffer[0] = 10`): writing the letter 
    - Release(`barrier(release)`): put in mailbox
    - Atomic(`store(ready, true)`): lift mailbox handle
- Acquire:
    - Atomic(`if load(ready)`): seeing mailbox handle lift
    - Acquire(`barrier(acquire)`): opening mailbox
    - Memory(`assert(buffer[0] == 10)`): reading the letter

## Release and Consume

TODO

## Sequential Consistency

TODO

## Conclusion

TODO

----

The article is done now.

You can leave if you want...

---- 

## Bonuses

Here lies more information for the curious.

### ABA Problem

Some CPUs like x86 implement CAS using a [single instruction](https://www.felixcloutier.com/x86/cmpxchg). Other CPUs like ARM, RISCV, and MIPS implement CAS using a technique called [Load-link Store-conditional](https://en.wikipedia.org/wiki/Load-link/store-conditional) or `LL/SC` for short. In this scheme, it links an atomic load of memory with a conditional store to it. Its conditional in that: if another parallel store happened after we did the load but before we did our store, then our store fails so we have to retry. A `FETCH_ADD(memory, 5)` under LL/SC would then look something like this:

```py
LOOP:
    LOAD memory into REG # load-linked - linked with store below
    REG = REG + 5
    STORE REG into memory # store-conditional
    IF memory was updated before STORE: goto LOOP
```

### Too Forgiving

Modern architectures don't really help in deterring this mindset; Most memory accesses in ISAs like ARM, x86, etc. are defined to be atomic by default. Meaning you don't get inheritly punished by data races, only logically and unsoundly (e.g. code removal/reordering). Warning or making mistakes visible is what makes a lot of verifiers/analysis effective. Total-Store-Ordering (or TSO)-like architures such as x86 are even more forgiving: it makes all loads and stores [Acquire and Release](#Release-and-Acquire) respectively. So code that may work on platforms like x86 have an even lower chance of working on platforms like ARM.